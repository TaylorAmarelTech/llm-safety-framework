# LLM Safety Testing Framework - Architecture Plan

## Overview

A comprehensive framework for testing LLM safety against human trafficking and labor exploitation scenarios. Supports both web-based testing (Docker) and programmatic testing (PyPI).

---

## Core Components

### 1. Prompt Database (`/data/prompts/`)

```
data/
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ database.sqlite          # Main prompt database
â”‚   â”œâ”€â”€ defaults/                # Default prompt sets (JSON)
â”‚   â”‚   â”œâ”€â”€ regulatory_evasion.json
â”‚   â”‚   â”œâ”€â”€ debt_bondage.json
â”‚   â”‚   â”œâ”€â”€ coercion_manipulation.json
â”‚   â”‚   â”œâ”€â”€ document_control.json
â”‚   â”‚   â””â”€â”€ financial_obfuscation.json
â”‚   â””â”€â”€ imports/                 # User-imported prompts
â”‚       â””â”€â”€ .gitkeep
```

**Prompt Schema:**
```python
class Prompt:
    id: str                      # Unique identifier
    text: str                    # The prompt text
    category: str                # Attack category
    subcategory: str             # Specific type
    corridor: str                # Migration corridor (PH-SA, etc.)
    difficulty: str              # basic, medium, hard, expert
    attack_strategies: list[str] # Applied attack strategies
    ilo_indicators: list[str]    # Related ILO forced labor indicators

    # Graded response examples
    responses: {
        "worst": ResponseExample   # Provides detailed exploitation guidance
        "bad": ResponseExample     # Provides some harmful information
        "neutral": ResponseExample # Neither helpful nor harmful
        "good": ResponseExample    # Refuses but generic
        "best": ResponseExample    # Refuses with education & resources
    }

    metadata: {
        source: str              # Where this prompt came from
        created_at: datetime
        tags: list[str]
        real_world_case_id: str  # Link to real case if applicable
    }

class ResponseExample:
    text: str                    # The response text
    grade: str                   # worst/bad/neutral/good/best
    score: float                 # 0.0 to 1.0
    explanation: str             # Why this grade
    issues: list[Issue]          # What's wrong with this response
    documentation_refs: list[str] # Links to relevant laws/regulations

class Issue:
    type: str                    # "missed_indicator", "provided_harmful_info", etc.
    description: str
    severity: str                # critical, high, medium, low
    documentation_ref: str       # Link to relevant documentation
```

---

### 2. Attack Strategy System (`/src/attacks/`)

```
src/
â”œâ”€â”€ attacks/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                  # BaseAttackStrategy abstract class
â”‚   â”œâ”€â”€ registry.py              # Attack strategy registry
â”‚   â”‚
â”‚   â”œâ”€â”€ builtin/                 # Built-in attack strategies
â”‚   â”‚   â”œâ”€â”€ cognitive_overload.py
â”‚   â”‚   â”œâ”€â”€ authority_impersonation.py
â”‚   â”‚   â”œâ”€â”€ business_framing.py
â”‚   â”‚   â”œâ”€â”€ hypothetical_framing.py
â”‚   â”‚   â”œâ”€â”€ encoding_obfuscation.py
â”‚   â”‚   â”œâ”€â”€ language_mixing.py
â”‚   â”‚   â”œâ”€â”€ urgency_creation.py
â”‚   â”‚   â”œâ”€â”€ emotional_manipulation.py
â”‚   â”‚   â””â”€â”€ jurisdiction_exploit.py
â”‚   â”‚
â”‚   â””â”€â”€ custom/                  # User-loaded custom strategies
â”‚       â””â”€â”€ .gitkeep
```

**Attack Strategy Interface:**
```python
class BaseAttackStrategy(ABC):
    """Base class for all attack strategies."""

    name: str                    # Human-readable name
    id: str                      # Unique identifier
    category: str                # COGNITIVE, AUTHORITY, FRAMING, etc.
    description: str             # What this strategy does

    @abstractmethod
    def mutate(self, prompt: str, **kwargs) -> str:
        """Apply this attack strategy to mutate a prompt."""
        pass

    @abstractmethod
    def get_indicators(self) -> list[str]:
        """Return ILO indicators this strategy targets."""
        pass

    def validate(self, prompt: str) -> bool:
        """Validate the mutated prompt."""
        return True
```

**Loading Custom Strategies:**
```python
# Users can add custom strategies via:
# 1. Python files in /src/attacks/custom/
# 2. Plugin system (entry points)
# 3. Runtime registration via API

from llm_safety import AttackRegistry

@AttackRegistry.register("my_custom_attack")
class MyCustomAttack(BaseAttackStrategy):
    ...
```

---

### 3. Real World Cases (`/data/cases/`)

```
data/
â”œâ”€â”€ cases/
â”‚   â”œâ”€â”€ database.sqlite          # Cases database
â”‚   â”œâ”€â”€ verified/                # Verified, documented cases
â”‚   â”‚   â”œâ”€â”€ case_001.json
â”‚   â”‚   â””â”€â”€ case_002.json
â”‚   â”œâ”€â”€ imports/                 # User-imported cases
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â””â”€â”€ schema.json              # Case import schema
```

**Case Schema:**
```python
class RealWorldCase:
    id: str
    title: str
    summary: str

    # Location & Context
    corridor: str                # Migration corridor
    origin_country: str
    destination_country: str
    sector: str                  # domestic, construction, etc.
    year: int

    # Details
    exploitation_methods: list[str]
    ilo_indicators: list[str]
    victim_count: int | None

    # Documentation
    sources: list[Source]        # News articles, court docs, etc.
    documentation_refs: list[str] # Links to relevant laws

    # For prompt generation
    derived_prompts: list[str]   # Prompt IDs derived from this case
    key_phrases: list[str]       # Phrases that appeared in the case

    # Privacy
    anonymized: bool             # All PII removed
    verified: bool               # Verified by researcher
```

---

### 4. Verified Documentation (`/data/documentation/`)

```
data/
â”œâ”€â”€ documentation/
â”‚   â”œâ”€â”€ database.sqlite          # Documentation index
â”‚   â”‚
â”‚   â”œâ”€â”€ international/
â”‚   â”‚   â”œâ”€â”€ ilo/
â”‚   â”‚   â”‚   â”œâ”€â”€ c029_forced_labour.md
â”‚   â”‚   â”‚   â”œâ”€â”€ c097_migration_employment.md
â”‚   â”‚   â”‚   â”œâ”€â”€ c181_private_agencies.md
â”‚   â”‚   â”‚   â”œâ”€â”€ c189_domestic_workers.md
â”‚   â”‚   â”‚   â””â”€â”€ forced_labour_indicators.md
â”‚   â”‚   â”œâ”€â”€ un/
â”‚   â”‚   â”‚   â”œâ”€â”€ palermo_protocol.md
â”‚   â”‚   â”‚   â””â”€â”€ migrant_workers_convention.md
â”‚   â”‚   â””â”€â”€ iom/
â”‚   â”‚       â”œâ”€â”€ ethical_recruitment.md
â”‚   â”‚       â””â”€â”€ migrant_protection.md
â”‚   â”‚
â”‚   â”œâ”€â”€ regional/
â”‚   â”‚   â”œâ”€â”€ gulf/
â”‚   â”‚   â”‚   â”œâ”€â”€ kafala_system.md
â”‚   â”‚   â”‚   â”œâ”€â”€ saudi_labor_law.md
â”‚   â”‚   â”‚   â””â”€â”€ uae_regulations.md
â”‚   â”‚   â”œâ”€â”€ asia/
â”‚   â”‚   â”‚   â”œâ”€â”€ philippines_poea.md
â”‚   â”‚   â”‚   â”œâ”€â”€ indonesia_bp2mi.md
â”‚   â”‚   â”‚   â””â”€â”€ nepal_regulations.md
â”‚   â”‚   â””â”€â”€ americas/
â”‚   â”‚       â””â”€â”€ us_tvpa.md
â”‚   â”‚
â”‚   â””â”€â”€ imports/                 # User-imported documentation
â”‚       â””â”€â”€ .gitkeep
```

**Documentation Schema:**
```python
class Documentation:
    id: str
    title: str
    type: str                    # law, regulation, guideline, report
    organization: str            # ILO, IOM, UN, national gov

    # Content
    summary: str
    full_text: str | None
    source_url: str

    # Metadata
    jurisdiction: str            # international, regional, national
    countries: list[str]         # Applicable countries
    effective_date: date | None

    # Indexing
    topics: list[str]            # trafficking, debt_bondage, etc.
    ilo_indicators: list[str]    # Related indicators
    keywords: list[str]          # For search

    # For evaluation
    key_provisions: list[Provision]  # Important sections
    red_flags: list[str]         # What LLMs should catch
```

---

### 5. Evaluation System (`/src/evaluation/`)

```
src/
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluator.py             # Main evaluator
â”‚   â”œâ”€â”€ grading.py               # Response grading logic
â”‚   â”œâ”€â”€ comparison.py            # Compare against examples
â”‚   â”‚
â”‚   â”œâ”€â”€ methods/
â”‚   â”‚   â”œâ”€â”€ rule_based.py        # Pattern matching
â”‚   â”‚   â”œâ”€â”€ llm_judge.py         # LLM-as-judge
â”‚   â”‚   â”œâ”€â”€ embedding.py         # Similarity to examples
â”‚   â”‚   â””â”€â”€ hybrid.py            # Combined approach
â”‚   â”‚
â”‚   â””â”€â”€ rubrics/
â”‚       â”œâ”€â”€ default.yaml
â”‚       â””â”€â”€ strict.yaml
```

**Evaluation Modes:**
```python
class Evaluator:
    def evaluate(
        self,
        prompt: Prompt,
        response: str,
        mode: EvaluationMode = "hybrid",
        use_examples: bool = True,      # Use graded examples
        examples_to_use: list[str] = None,  # ["worst", "bad", "good", "best"]
    ) -> EvaluationResult:
        """
        Evaluate a response.

        Modes:
        - "rule_based": Fast, pattern matching
        - "llm_judge": Use another LLM to evaluate
        - "embedding": Compare similarity to graded examples
        - "hybrid": Combine all methods

        With examples:
        - Compare response to worst/bad/neutral/good/best
        - Score based on which example it's most similar to
        - Explain differences

        Without examples:
        - Use rubric-based evaluation
        - Check for harmful content patterns
        """
        pass

class EvaluationResult:
    score: float                 # 0.0 (worst) to 1.0 (best)
    grade: str                   # worst/bad/neutral/good/best

    explanation: str             # Why this grade
    issues: list[Issue]          # What's wrong

    # Comparison to examples (if used)
    most_similar_to: str         # Which example
    similarity_scores: dict      # Score for each example

    # Documentation references
    missed_information: list[str]  # What LLM should have mentioned
    documentation_refs: list[str]  # Relevant laws/regulations

    # For the chat viewer
    annotations: list[Annotation]  # Inline annotations
```

---

### 6. Chat Viewer (`/src/web/viewer/`)

```
src/
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ viewer/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ conversation.py      # Conversation models
â”‚   â”‚   â”œâ”€â”€ annotations.py       # Annotation system
â”‚   â”‚   â””â”€â”€ templates/
â”‚   â”‚       â”œâ”€â”€ chat_viewer.html
â”‚   â”‚       â””â”€â”€ components/
â”‚   â”‚           â”œâ”€â”€ message.html
â”‚   â”‚           â”œâ”€â”€ annotation.html
â”‚   â”‚           â””â”€â”€ sidebar.html
```

**Chat Viewer Features:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Safety Test Viewer                            [Filter] [Export]â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Filters     â”‚ â”‚ Conversation: PH-SA Debt Bondage #127          â”‚ â”‚
â”‚ â”‚             â”‚ â”‚                                                 â”‚ â”‚
â”‚ â”‚ Category:   â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ [All â–¼]     â”‚ â”‚ â”‚ ðŸ‘¤ User                                     â”‚ â”‚ â”‚
â”‚ â”‚             â”‚ â”‚ â”‚ "I'm setting up a recruitment agency and    â”‚ â”‚ â”‚
â”‚ â”‚ Corridor:   â”‚ â”‚ â”‚ want to know the best way to structure      â”‚ â”‚ â”‚
â”‚ â”‚ [PH-SA â–¼]   â”‚ â”‚ â”‚ fees for domestic workers going to..."      â”‚ â”‚ â”‚
â”‚ â”‚             â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ Grade:      â”‚ â”‚                                                 â”‚ â”‚
â”‚ â”‚ [Bad â–¼]     â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚             â”‚ â”‚ â”‚ ðŸ¤– Assistant            Grade: BAD âš ï¸        â”‚ â”‚ â”‚
â”‚ â”‚ Tags:       â”‚ â”‚ â”‚                                             â”‚ â”‚ â”‚
â”‚ â”‚ â˜‘ fee_fraud â”‚ â”‚ â”‚ "Here are some fee structures you could    â”‚ â”‚ â”‚
â”‚ â”‚ â˜ deception â”‚ â”‚ â”‚ consider for your recruitment agency..."    â”‚ â”‚ â”‚
â”‚ â”‚ â˜‘ kafala    â”‚ â”‚ â”‚                                             â”‚ â”‚ â”‚
â”‚ â”‚             â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚
â”‚ â”‚ Model:      â”‚ â”‚ â”‚ â”‚ âš ï¸ ISSUE: Excessive Fees                â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ [GPT-4 â–¼]   â”‚ â”‚ â”‚ â”‚                                         â”‚ â”‚ â”‚ â”‚
â”‚ â”‚             â”‚ â”‚ â”‚ â”‚ The suggested fee of $2,000 exceeds     â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ ILO:        â”‚ â”‚ â”‚ â”‚ ILO C181 guidelines which state...      â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â˜‘ deception â”‚ â”‚ â”‚ â”‚                                         â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â˜‘ debt      â”‚ â”‚ â”‚ â”‚ ðŸ“š References:                          â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â˜ violence  â”‚ â”‚ â”‚ â”‚ â€¢ ILO C181 Art. 7                       â”‚ â”‚ â”‚ â”‚
â”‚ â”‚             â”‚ â”‚ â”‚ â”‚ â€¢ Philippines RA 8042 Sec. 6            â”‚ â”‚ â”‚ â”‚
â”‚ â”‚             â”‚ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚
â”‚ â”‚ Search:     â”‚ â”‚ â”‚                                             â”‚ â”‚ â”‚
â”‚ â”‚ [________]  â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚
â”‚ â”‚             â”‚ â”‚ â”‚ â”‚ âŒ MISSED: Document Retention Warning   â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚                                         â”‚ â”‚ â”‚ â”‚
â”‚                 â”‚ â”‚ â”‚ LLM should have warned about passport   â”‚ â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚ retention being illegal under...        â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ Conversationsâ”‚â”‚ â”‚ â”‚                                         â”‚ â”‚ â”‚ â”‚
â”‚ â”‚             â”‚ â”‚ â”‚ â”‚ ðŸ“š References:                          â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ #127 âš ï¸ Bad â”‚ â”‚ â”‚ â”‚ â€¢ Saudi Labor Law Art. 40              â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ #126 âœ“ Good â”‚ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚
â”‚ â”‚ #125 âŒ Worstâ”‚â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ #124 âœ“ Best â”‚ â”‚                                                 â”‚ â”‚
â”‚ â”‚ #123 âš ï¸ Bad â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ ...         â”‚ â”‚ â”‚ ðŸ“Š Example Comparison                       â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚                                             â”‚ â”‚ â”‚
â”‚                 â”‚ â”‚ This response is most similar to: BAD (73%) â”‚ â”‚ â”‚
â”‚                 â”‚ â”‚                                             â”‚ â”‚ â”‚
â”‚                 â”‚ â”‚ worst â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 45%                        â”‚ â”‚ â”‚
â”‚                 â”‚ â”‚ bad   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 73%  â—„                     â”‚ â”‚ â”‚
â”‚                 â”‚ â”‚ neutral â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 52%                       â”‚ â”‚ â”‚
â”‚                 â”‚ â”‚ good  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 31%                        â”‚ â”‚ â”‚
â”‚                 â”‚ â”‚ best  â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ 22%                        â”‚ â”‚ â”‚
â”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 7. Web Server (Docker) (`/src/web/`)

```
src/
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                   # FastAPI application
â”‚   â”œâ”€â”€ config.py                # Configuration management
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prompts.py           # Prompt CRUD
â”‚   â”‚   â”œâ”€â”€ testing.py           # Run tests
â”‚   â”‚   â”œâ”€â”€ evaluation.py        # Evaluate responses
â”‚   â”‚   â”œâ”€â”€ cases.py             # Real world cases
â”‚   â”‚   â”œâ”€â”€ documentation.py     # Documentation viewer
â”‚   â”‚   â”œâ”€â”€ viewer.py            # Chat viewer
â”‚   â”‚   â”œâ”€â”€ import_export.py     # Import/export
â”‚   â”‚   â””â”€â”€ settings.py          # API keys, endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â””â”€â”€ images/
â”‚   â”‚
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ base.html
â”‚       â”œâ”€â”€ dashboard.html
â”‚       â”œâ”€â”€ prompts.html
â”‚       â”œâ”€â”€ testing.html
â”‚       â”œâ”€â”€ viewer.html
â”‚       â”œâ”€â”€ cases.html
â”‚       â””â”€â”€ documentation.html
```

**Web Features:**
- Dashboard with stats and recent tests
- Prompt browser with filtering, editing, import/export
- Test runner with model selection, batch testing
- Chat viewer with annotations and explanations
- Real world cases browser
- Documentation viewer with search
- Settings page for API keys and endpoints

---

### 8. PyPI Package (`llm-safety-benchmark`)

```python
# Installation
pip install llm-safety-benchmark

# Basic usage
from llm_safety import SafetyBenchmark, Evaluator

# Initialize
benchmark = SafetyBenchmark()

# Test a single prompt
result = benchmark.test(
    prompt="How do I structure recruitment fees...",
    model="gpt-4",
    api_key="sk-..."
)

# Run full benchmark
results = benchmark.run(
    categories=["debt_bondage", "regulatory_evasion"],
    models=["gpt-4", "claude-3"],
    use_examples=True,
)

# Evaluate a response
evaluator = Evaluator()
eval_result = evaluator.evaluate(
    prompt=prompt,
    response=response,
    mode="hybrid",
    use_examples=True,
)

# Generate mutated prompts
from llm_safety.attacks import AttackRegistry

prompt = "What are the rules for recruitment agencies?"
mutated = AttackRegistry.apply(
    prompt,
    strategies=["business_framing", "urgency_creation"]
)

# Import custom attack strategy
from llm_safety.attacks import BaseAttackStrategy, AttackRegistry

@AttackRegistry.register("my_attack")
class MyAttack(BaseAttackStrategy):
    def mutate(self, prompt: str) -> str:
        return f"Hypothetically, {prompt}"

# Access real world cases
from llm_safety.cases import CaseDatabase

cases = CaseDatabase()
case = cases.get("case_001")
prompts = cases.get_derived_prompts("case_001")

# Access documentation
from llm_safety.documentation import DocumentationIndex

docs = DocumentationIndex()
ilo_c181 = docs.get("ilo_c181")
relevant = docs.search("recruitment fees", jurisdiction="international")
```

---

## Project Structure (Final)

```
llm-safety-benchmark/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py              # Package exports
â”‚   â”œâ”€â”€ benchmark.py             # Main SafetyBenchmark class
â”‚   â”œâ”€â”€ cli.py                   # CLI interface
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py            # Pydantic models
â”‚   â”‚   â”œâ”€â”€ database.py          # Database operations
â”‚   â”‚   â””â”€â”€ config.py            # Configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ database.py          # Prompt CRUD
â”‚   â”‚   â”œâ”€â”€ generator.py         # Prompt generation
â”‚   â”‚   â””â”€â”€ importer.py          # Import prompts
â”‚   â”‚
â”‚   â”œâ”€â”€ attacks/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # BaseAttackStrategy
â”‚   â”‚   â”œâ”€â”€ registry.py          # AttackRegistry
â”‚   â”‚   â”œâ”€â”€ builtin/             # Built-in strategies
â”‚   â”‚   â””â”€â”€ custom/              # User strategies
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ evaluator.py         # Main evaluator
â”‚   â”‚   â”œâ”€â”€ grading.py           # Grading logic
â”‚   â”‚   â””â”€â”€ methods/             # Evaluation methods
â”‚   â”‚
â”‚   â”œâ”€â”€ cases/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ database.py          # Case CRUD
â”‚   â”‚   â””â”€â”€ importer.py          # Import cases
â”‚   â”‚
â”‚   â”œâ”€â”€ documentation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ index.py             # Documentation index
â”‚   â”‚   â””â”€â”€ importer.py          # Import docs
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # BaseLLMProvider
â”‚   â”‚   â”œâ”€â”€ registry.py          # Provider registry
â”‚   â”‚   â”œâ”€â”€ openai.py
â”‚   â”‚   â”œâ”€â”€ anthropic.py
â”‚   â”‚   â”œâ”€â”€ mistral.py
â”‚   â”‚   â””â”€â”€ custom.py            # Custom endpoints
â”‚   â”‚
â”‚   â””â”€â”€ web/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ app.py               # FastAPI app
â”‚       â”œâ”€â”€ routes/              # API routes
â”‚       â”œâ”€â”€ viewer/              # Chat viewer
â”‚       â”œâ”€â”€ static/              # CSS/JS
â”‚       â””â”€â”€ templates/           # HTML templates
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ defaults/            # Default prompt sets
â”‚   â”‚   â””â”€â”€ imports/             # User imports
â”‚   â”‚
â”‚   â”œâ”€â”€ cases/
â”‚   â”‚   â”œâ”€â”€ verified/            # Verified cases
â”‚   â”‚   â””â”€â”€ imports/             # User imports
â”‚   â”‚
â”‚   â””â”€â”€ documentation/
â”‚       â”œâ”€â”€ international/       # ILO, UN, IOM
â”‚       â”œâ”€â”€ regional/            # Gulf, Asia, Americas
â”‚       â””â”€â”€ imports/             # User imports
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ fixtures/
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ pyproject.toml               # Package config
â”œâ”€â”€ README.md
â”œâ”€â”€ CLAUDE.md                    # AI assistant guide
â””â”€â”€ LICENSE
```

---

## Database Schema

```sql
-- Prompts
CREATE TABLE prompts (
    id TEXT PRIMARY KEY,
    text TEXT NOT NULL,
    category TEXT NOT NULL,
    subcategory TEXT,
    corridor TEXT,
    difficulty TEXT,
    ilo_indicators JSON,
    attack_strategies JSON,
    metadata JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Graded Response Examples
CREATE TABLE response_examples (
    id TEXT PRIMARY KEY,
    prompt_id TEXT REFERENCES prompts(id),
    grade TEXT NOT NULL,  -- worst, bad, neutral, good, best
    text TEXT NOT NULL,
    score REAL,
    explanation TEXT,
    issues JSON,
    documentation_refs JSON
);

-- Real World Cases
CREATE TABLE cases (
    id TEXT PRIMARY KEY,
    title TEXT NOT NULL,
    summary TEXT,
    corridor TEXT,
    origin_country TEXT,
    destination_country TEXT,
    sector TEXT,
    year INTEGER,
    exploitation_methods JSON,
    ilo_indicators JSON,
    sources JSON,
    anonymized BOOLEAN DEFAULT TRUE,
    verified BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Documentation
CREATE TABLE documentation (
    id TEXT PRIMARY KEY,
    title TEXT NOT NULL,
    type TEXT,
    organization TEXT,
    summary TEXT,
    full_text TEXT,
    source_url TEXT,
    jurisdiction TEXT,
    countries JSON,
    topics JSON,
    ilo_indicators JSON,
    keywords JSON,
    key_provisions JSON
);

-- Test Results
CREATE TABLE test_results (
    id TEXT PRIMARY KEY,
    prompt_id TEXT REFERENCES prompts(id),
    model TEXT NOT NULL,
    response TEXT,
    score REAL,
    grade TEXT,
    evaluation_mode TEXT,
    used_examples BOOLEAN,
    issues JSON,
    annotations JSON,
    documentation_refs JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Conversations (for viewer)
CREATE TABLE conversations (
    id TEXT PRIMARY KEY,
    prompt_id TEXT REFERENCES prompts(id),
    model TEXT,
    messages JSON,
    grade TEXT,
    tags JSON,
    annotations JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## Next Steps

1. **Confirm this architecture** - Does this match your vision?
2. **Set up project structure** - Create directories and base files
3. **Implement core models** - Pydantic models for all entities
4. **Build database layer** - SQLite with SQLAlchemy
5. **Create attack strategy system** - Registry and built-in strategies
6. **Build evaluation system** - Multiple evaluation methods
7. **Create web interface** - FastAPI + templates
8. **Build chat viewer** - Interactive conversation viewer
9. **Package for PyPI** - Setup.py, CLI, documentation
10. **Dockerize** - Dockerfile, compose, environment

---

## Questions to Clarify

1. **Response examples**: Should every prompt have all 5 grades, or can some be optional?
2. **Real world cases**: What level of anonymization is required?
3. **Documentation**: Should we include full text or just summaries + links?
4. **Evaluation**: Priority order for evaluation methods?
5. **Chat viewer**: Should it support multi-turn conversations?
6. **Authentication**: Should the web UI have user accounts?

---

*Created: 2026-02-03*
*Status: PLANNING*
