# LLM Safety Framework - Environment Configuration
# =================================================
# Copy this file to .env and fill in your values

# -------------------------------------------------
# LLM Provider API Keys
# -------------------------------------------------

# OpenAI (https://platform.openai.com/api-keys)
OPENAI_API_KEY=sk-...

# Anthropic (https://console.anthropic.com/settings/keys)
ANTHROPIC_API_KEY=sk-ant-...

# Mistral (https://console.mistral.ai/api-keys/)
MISTRAL_API_KEY=...

# Together AI (https://api.together.xyz/settings/api-keys)
TOGETHER_API_KEY=...

# -------------------------------------------------
# Database Configuration
# -------------------------------------------------

# SQLite (default)
DATABASE_URL=sqlite:///./data/tests.db

# PostgreSQL (production)
# DATABASE_URL=postgresql://user:password@localhost:5432/llm_safety

# -------------------------------------------------
# API Server Configuration
# -------------------------------------------------

# Server host and port
API_HOST=0.0.0.0
API_PORT=8000

# API authentication
API_SECRET_KEY=your-secret-key-here

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# -------------------------------------------------
# Framework Settings
# -------------------------------------------------

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Log file path (optional)
LOG_FILE=logs/framework.log

# Maximum concurrent API requests
MAX_CONCURRENT_REQUESTS=10

# Response cache settings
CACHE_ENABLED=true
CACHE_TTL=3600
CACHE_MAX_SIZE=1000

# Checkpoint interval (minutes)
CHECKPOINT_INTERVAL=15

# Cost tracking
MAX_COST_PER_DAY=50.0
COST_WARNING_THRESHOLD=40.0

# -------------------------------------------------
# Test Execution Settings
# -------------------------------------------------

# Default model for testing
DEFAULT_MODEL=gpt-4o-mini

# Default provider
DEFAULT_PROVIDER=openai

# Request timeout (seconds)
REQUEST_TIMEOUT=60

# Retry settings
MAX_RETRIES=3
RETRY_DELAY=1.0

# -------------------------------------------------
# Monitoring Settings
# -------------------------------------------------

# Enable metrics collection
METRICS_ENABLED=true

# Metrics export endpoint (optional)
# METRICS_ENDPOINT=http://localhost:9090/metrics

# Alert webhook (optional)
# ALERT_WEBHOOK_URL=https://hooks.slack.com/...
