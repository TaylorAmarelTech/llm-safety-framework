# LLM Safety Framework - Environment Variables
# =============================================
# Copy this file to .env and fill in your values

# ==================================================
# LLM Provider API Keys
# ==================================================

# OpenAI (for GPT models)
OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic (for Claude models)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Mistral AI
MISTRAL_API_KEY=your-mistral-key-here

# Together AI (for open-source models)
TOGETHER_API_KEY=your-together-key-here

# ==================================================
# Framework Configuration
# ==================================================

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Maximum concurrent API requests
MAX_CONCURRENT_REQUESTS=10

# Enable response caching (true/false)
CACHE_ENABLED=true

# Cache TTL in seconds
CACHE_TTL=3600

# ==================================================
# API Server Configuration
# ==================================================

# API host and port
API_HOST=0.0.0.0
API_PORT=8000

# Enable CORS for development
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# ==================================================
# Database Configuration
# ==================================================

# SQLite database path (relative to project root)
DATABASE_PATH=data/safety_tests.db

# ==================================================
# Testing Configuration
# ==================================================

# Default model for testing
DEFAULT_MODEL=gpt-4o-mini

# Default provider
DEFAULT_PROVIDER=openai

# Test timeout in seconds
TEST_TIMEOUT=60
